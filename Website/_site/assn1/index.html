<html>
  <!-- please find the included snippets in the /_includes directory -->
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500|Playfair+Display:400,700" rel="stylesheet">

  <title>Assignment #1: Probability and Statistics (due 02/03)</title>
  <meta name="description" content="Problem 1 [20 Points]">

  <link rel="canonical" href="https://www.seas.upenn.edu/~enm5310/assn1/">
  <link rel="alternate" type="application/rss+xml" title="Data-driven Modeling and Probabilistic Scientific Computing" href="https://www.seas.upenn.edu/~enm5310/feed.xml">
  <link rel="shortcut icon" type ="image/png" href="https://www.seas.upenn.edu/~enm5310/PredictiveIntelligence_logo.png">
  <!-- Styles -->
  <link rel="stylesheet" href="/~enm5310/css/foundation.css">
  <!-- LaTeX support with MathJax -->
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>


  <body>
    <div class="">
  <nav class="top-bar">
    <div class="top-bar-left">
      <ul class="menu">
	<li><a href="https://www.seas.upenn.edu/~enm5310"><img src="https://www.seas.upenn.edu/~enm5310/PredictiveIntelligence_logo.png" width="30" height="30"></a></li>
	<li><a href="https://github.com/PredictiveIntelligenceLab/ENM5310"><img src="https://www.seas.upenn.edu/~enm5310/GitHub_logo.png" width="30" height="30"></a></li>
        <li><a href="https://www.seas.upenn.edu/~enm5310">Data-driven Modeling and Probabilistic Scientific Computing, Spring 2023</a></li>
        <li><a href="/~enm5310/syllabus">Syllabus</a></li>
        <li><a href="/~enm5310/duedates">Due Dates</a></li>
        <li><a href="/~enm5310/policies">Policies</a></li>
      </ul>
    </div>
  </nav>
</div>

    
   <div class="row main">
      <h3>Assignment #1: Probability and Statistics (due 02/03)</h3>
<h2 id="problem-1-20-points">Problem 1 [20 Points]</h2>

<h3 id="subproblem-1-10-points">Subproblem 1 [10 Points]</h3>

<p>Consider a coin that comes up heads with probability \(p\) and tails with probability \(1-p\). Let \(q_n\) be the probability of obtaining even number of heads in \(n\) independent tosses. Derive a recursion that relates \(q_n\) to \(q_{n-1}\) and establish the formula</p>

\[q_n = \frac{1+(1-2p)^n}{2}.\]

<h3 id="subproblem-2-10-points">Subproblem 2 [10 Points]</h3>

<p>Let \(X\) and \(Y\) have joint PDF 
\(f_{X,Y}(x,y) = \begin{cases}
C e^{-(ax+by)} &amp; x,y \geq 0\\
0 &amp; \text{otherwise}
\end{cases},\)
where, \(a, b &gt; 0\) are constants.</p>

<ul>
  <li>Determine the constant \(C\).</li>
  <li>Find the marginal density of \(X\) and \(Y\). What can you infer from them?</li>
  <li>Find \(\mathbb{E}(Y \mid X&gt; \frac{\exp(a^2 + b^2)}{a^4 + b^4})\).</li>
</ul>

<h2 id="problem-2-20-points">Problem 2 [20 points]</h2>

<p>Let \(S_1,S_2,\ldots,S_n\) be a partition of the sample space \(\Omega\).</p>
<ul>
  <li>Show that for any event \(A\),
\(\mathbb{P}(A) = \sum_{i=1}^n \mathbb{P}\left({A \cap S_i}\right)\).</li>
  <li>Use the previous part to show that, for events \(A\), \(B\) and \(C\),
\(\mathbb{P}\left({A}\right) = \mathbb{P}\left({A \cap B}\right) + \mathbb{P}\left({A \cap C}\right) + \mathbb{P}\left({A \cap B^c \cap C^c}\right) - \mathbb{P}\left({A \cap B \cap C}\right)\).</li>
  <li>Prove that for any two events \(A\) and \(B\), we have
\(\mathbb{P} (A \cap B) \geq \mathbb{P}(A) + \mathbb{P}(B) - 1\).</li>
  <li>Using the above, establish the following generalization:
\(\mathbb{P}(A_1 \cap A_2 \cap \cdots \cap A_n) \geq \mathbb{P}(A_1) + \mathbb{P}(A_2) + \cdots + \mathbb{P}(A_n) - (n-1)\).</li>
</ul>

<p><strong>[You will need to argue logically using only the basic axioms of probability. Drawing a diagram is not enough.]</strong></p>

<h2 id="problem-3-20-points">Problem 3 [20 Points]</h2>

<h3 id="subproblem-1-10-points-1">Subproblem 1 [10 Points]</h3>

<ul>
  <li>If \(X_1,X_2,\ldots,X_n\) are independent random variables having the same probability density function \(f_X(x)\), what is the probability density function for the random variable \(Y=\text{min}\{X_1,X_2,\ldots,X_n\}\)?</li>
  <li>Consider two continuous random variables \(Y\) and \(Z\) and a random variable \(X\) that is equal to \(Y\) with a probability \(p\) and equals \(Z\) with a probability \(1-p\). Obtain the pdf of \(X\) interms of the pdfâ€™s of \(Y\) and \(Z\).</li>
</ul>

<h3 id="subproblem-2-10-points-1">Subproblem 2 [10 Points]</h3>

<p>The Laplace distribution is given by
\(p(x | \mu, b) = \frac{1}{2 b} \exp \left(-\frac{|x - \mu|}{b}\right)\).</p>

<p>Consider a mixture of three Laplace distributions:
\(p(x) = \alpha p_1(x) + \beta p_2(x) + \gamma p_3(x)\),
where \(\alpha, \beta, \gamma \in [0,1]\) are mixture weights satisfying \(\alpha + \beta + \gamma = 1\) and \(p_1(x)\), \(p_2(x)\) and \(p_3(x)\) are Laplace distributions with different parameters \((\mu_1, b_1) \neq (\mu_2, b_2) \neq (\mu_3, b_3)\).</p>

<p>Derive the expectation and variance of \(p(x)\), analytically, using their definitions.</p>

<h2 id="problem-4-20-points">Problem 4 [20 Points]</h2>

<p>As mentioned in class the Gaussian has nice properties which makes it a fundamental tool in statistical infererence. The standard normal \(\mathcal{N}(\mathbf{x}; \mathbf{\mu}, \mathbf{\Sigma})\) is defined as</p>

\[\mathcal{N}(\mathbf{x}; \mathbf{\mu}, \mathbf{\Sigma}) = \frac{1}{\sqrt{(2 \pi)^n |\mathbf{\Sigma}|}} \exp \left[ -\frac{1}{2} (\mathbf{x} - \mathbf{\mu})^\top \Sigma^{-1} (\mathbf{x} - \mathbf{\mu}) \right].\]

<ul>
  <li>Prove that if \(x \in \mathbb{R}^d\) is normally distributed, every affine transformation \(y = A x + b\) also has a Gaussian distribution. Find its mean and covariance.</li>
  <li>Analytically find the KL divergence \(\mathbb{KL}(P \lvert\lvert Q)\) between two multivariate normal distributions \(p(x) \sim \mathcal{N}(\mathbf{x}; \mathbf{\mu}_1, \mathbf{\Sigma}_1)\) and \(q(x) \sim \mathcal{N}(\mathbf{x}; \mathbf{\mu}_2, \mathbf{\Sigma}_2)\).</li>
</ul>

<h2 id="problem-5-20-points">Problem 5 [20 Points]</h2>

<p>Consider a two-dimensional random variable \(z=(z_1,z_2)\) distributed as</p>

\[p(z_1,z_2) = \mathcal{N}\left(\left[\begin{matrix} 0 \\ 0 \end{matrix}\right],
\left[\begin{matrix} 1 &amp; 0 \\ 0 &amp; 1 \end{matrix}\right]\right).\]

<p>Also consider a transformation \(z_1 = g_1(x_1) = x_1^3 - 6x_1^2 + 12x_1 - 8\) whose inverse mapping is \(x_1 = g_1^{-1}(z_1) = z_1^{1/3} + 2\), and \(z_2 = g_2(x_2) = x_2 + 1\) whose inverse mapping is \(x_2 = g_2^{-1}(z_2) = z_2 - 1\). Generate \(5000\) realizations for \((z_1, z_2)\) from \(p(z_1,z_2)\) and compute the corresponding \((x_1, x_2)\) pairs according to the given transformation. Then, maximize the log-likelihood of the \((x_1, x_2)\) observations to estimate the parameters of the forward mapping that transforms \(p(z)\) into \(p(x)\) (consider a polynomial basis). Report the learned parameters, log-likelihood loss and a visualization of \(p(x)\) at every step of your gradient ascent algorithm.</p>



<!-- the pager module looks at pages in the same category -->

<div class="expanded button-group">
  
  <a class="button expanded warning" href="/~enm5310/assn0/">previous</a>
  
  
</div>



    </div>

        <script src="https://www.seas.upenn.edu/~enm5310/js/vendor/jquery.js"></script>
    <script src="https://www.seas.upenn.edu/~enm5310/js/vendor/foundation.min.js"></script>
    <script src="https://www.seas.upenn.edu/~enm5310/js/vendor/what-input.js"></script>
    <script src="https://www.seas.upenn.edu/~enm5310/js/app.js"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-112328818-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-112328818-1');
</script>

    
  </body>

</html>
